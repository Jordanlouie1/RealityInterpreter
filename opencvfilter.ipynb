{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import YouTubeVideo, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 21:48:46.840 python[51818:1770288] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    }
   ],
   "source": [
    "# Filter modes\n",
    "PREVIEW = 0       # Preview mode\n",
    "BLUR = 1          # Blur mode\n",
    "FEATURES = 2      # Features mode\n",
    "CANNY = 3         # Canny mode\n",
    "GRAYSCALE = 4     # Grayscale mode\n",
    "LAPLACIAN = 5     # Laplacian edge detection mode\n",
    "THRESHOLD = 6     # Threshold mode\n",
    "BILATERAL = 7     # Bilateral filtering mode\n",
    "\n",
    "# Animal types\n",
    "DOG = 8\n",
    "SNAKE = 9\n",
    "BIRD = 10\n",
    "HUMAN = 11\n",
    "INSECT = 12\n",
    "ELEPHANT = 13\n",
    "\n",
    "\n",
    "# Parameters for feature detection\n",
    "features_params = dict(maxCorners=500, qualityLevel=0.1, minDistance=15, blockSize=9)\n",
    "\n",
    "s = 0  # for default camera\n",
    "\n",
    "# Set default filter mode to preview\n",
    "image_filter = SNAKE\n",
    "\n",
    "source = cv2.VideoCapture(s)\n",
    "\n",
    "alive = True\n",
    "window_name = \"Camera Filters\"\n",
    "cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "result = None\n",
    "\n",
    "mode_names = {\n",
    "    PREVIEW: \"Preview\",\n",
    "    BLUR: \"Blur\",\n",
    "    FEATURES: \"Features\",\n",
    "    CANNY: \"Canny\",\n",
    "    GRAYSCALE: \"Grayscale\",\n",
    "    LAPLACIAN: \"Laplacian\",\n",
    "    THRESHOLD: \"Threshold\",\n",
    "    BILATERAL: \"Bilateral\",\n",
    "    DOG: \"Dog\",\n",
    "    SNAKE: \"Snake\",\n",
    "    BIRD: \"Bird\",\n",
    "    HUMAN: \"Human\",\n",
    "    INSECT: \"Insect\",\n",
    "    ELEPHANT: \"Elephant\"\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while alive:\n",
    "    has_frame, frame = source.read()\n",
    "\n",
    "    if not has_frame:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    try:\n",
    "        if image_filter == HUMAN:\n",
    "            result = frame\n",
    "\n",
    "        elif image_filter == BLUR:\n",
    "            result = cv2.GaussianBlur(frame, (21, 21), 0)\n",
    "\n",
    "        elif image_filter == CANNY:\n",
    "            result = cv2.Canny(frame, 30, 200)\n",
    "\n",
    "        elif image_filter == FEATURES:\n",
    "            result = frame\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            corners = cv2.goodFeaturesToTrack(frame_gray, **features_params)\n",
    "            if corners is not None:\n",
    "                corners = np.intp(corners)\n",
    "                for corner in corners:\n",
    "                    x, y = corner.ravel()\n",
    "                    cv2.circle(result, (x, y), 10, (0, 255, 0), 1)\n",
    "\n",
    "        elif image_filter == GRAYSCALE:\n",
    "            result = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        elif image_filter == LAPLACIAN:\n",
    "            result = cv2.Laplacian(frame, cv2.CV_64F)\n",
    "\n",
    "        elif image_filter == THRESHOLD:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            _, result = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        elif image_filter == BILATERAL:\n",
    "            result = cv2.bilateralFilter(frame, 9, 75, 75)\n",
    "\n",
    "        elif image_filter == SNAKE:\n",
    "            blurred = cv2.GaussianBlur(frame, (35, 35), 0)\n",
    "\n",
    "            # 2. Convert to grayscale (snakes are not sensitive to color)\n",
    "            gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # 3. Apply a heatmap-like effect to simulate heat vision\n",
    "            # Use color mapping (COLORMAP_JET mimics infrared heat detection)\n",
    "            heatmap = cv2.applyColorMap(gray, cv2.COLORMAP_JET)\n",
    "\n",
    "            # 4. Apply Canny edge detection to simulate motion detection or sensing contours\n",
    "            edges = cv2.Canny(gray, 50, 150)\n",
    "            edges_colored = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  # Convert edges to 3 channels\n",
    "\n",
    "            # 5. Combine the heatmap and edges for a final snake-vision-like effect\n",
    "            combined = cv2.addWeighted(heatmap, 0.8, edges_colored, 0.2, 0)\n",
    "\n",
    "            result = combined\n",
    "\n",
    "        elif image_filter == DOG:\n",
    "            lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "            # 2. Split LAB channels (L: lightness, A: green to red, B: blue to yellow)\n",
    "            l, a, b = cv2.split(lab)\n",
    "\n",
    "            # 3. Shift the color channels to simulate dichromatic vision (blue/yellow only)\n",
    "            # Reduce the A channel (green-red) to simulate the lack of red perception\n",
    "            a[:] = 128  # Neutralize red-green sensitivity\n",
    "            # Increase the B channel (blue-yellow) slightly to enhance the yellow-blue vision\n",
    "            b[:] = np.clip(b * 1.2, 0, 255)\n",
    "\n",
    "            # 4. Merge the modified channels back\n",
    "            modified_lab = cv2.merge([l, a, b])\n",
    "\n",
    "            # 5. Convert back to BGR color space\n",
    "            dog_color_vision = cv2.cvtColor(modified_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "            # 6. Apply a slight Gaussian blur to simulate lower acuity\n",
    "            blurred = cv2.GaussianBlur(dog_color_vision, (11, 11), 0)\n",
    "\n",
    "            # 7. Adjust contrast and brightness (dogs see better in low light)\n",
    "            contrast = 1.2  # Increase contrast\n",
    "            brightness = 10  # Increase brightness slightly\n",
    "\n",
    "            adjusted_frame = cv2.convertScaleAbs(blurred, alpha=contrast, beta=brightness)\n",
    "\n",
    "            result = adjusted_frame\n",
    "\n",
    "        elif image_filter == INSECT:\n",
    "            # Step 1: Apply fisheye effect to simulate wide-angle insect vision\n",
    "\n",
    "            pixel_size=20\n",
    "            contrast=1.5\n",
    "            brightness=0\n",
    "\n",
    "            height, width = frame.shape[:2]\n",
    "            K = np.array([[width, 0, width//2],\n",
    "                        [0, height, height//2],\n",
    "                        [0, 0, 1]])\n",
    "            D = np.array([-0.4, 0.2, 0, 0])  # Distortion coefficients\n",
    "            map1, map2 = cv2.initUndistortRectifyMap(K, D, None, K, (width, height), 5)\n",
    "            fisheye_image = cv2.remap(frame, map1, map2, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            # Step 2: Pixelate the image to simulate the compound eye's pixelated vision\n",
    "            small = cv2.resize(fisheye_image, (width // pixel_size, height // pixel_size), interpolation=cv2.INTER_LINEAR)\n",
    "            pixelated = cv2.resize(small, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # Step 3: Simulate UV light vision by shifting colors to blue/violet tones\n",
    "            hsv = cv2.cvtColor(pixelated, cv2.COLOR_BGR2HSV)\n",
    "            hsv[:, :, 0] = (hsv[:, :, 0] + 40) % 180  # Shift hue channel to simulate UV vision\n",
    "            uv_vision = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "            # Step 4: Adjust contrast and brightness to simulate motion sensitivity\n",
    "            final_frame = cv2.convertScaleAbs(uv_vision, alpha=contrast, beta=brightness)\n",
    "\n",
    "            result = final_frame\n",
    "\n",
    "        elif image_filter == ELEPHANT:\n",
    "             # Step 1: Convert to the LAB color space (to work with lightness and color channels)\n",
    "            lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "            # Step 2: Modify color channels to simulate dichromatic (blue/yellow) vision\n",
    "            l, a, b = cv2.split(lab)\n",
    "\n",
    "            # Neutralize the red-green sensitivity (set the A channel to a neutral value)\n",
    "            a[:] = 128\n",
    "\n",
    "            # Enhance the blue-yellow perception (increase B channel)\n",
    "            b[:] = np.clip(b * 1.1, 0, 255)\n",
    "\n",
    "            # Merge the modified LAB channels back\n",
    "            lab_modified = cv2.merge([l, a, b])\n",
    "\n",
    "            # Convert back to BGR color space for further processing\n",
    "            color_adjusted = cv2.cvtColor(lab_modified, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "            # Step 3: Apply Gaussian blur to simulate blurry vision\n",
    "            blurred = cv2.GaussianBlur(color_adjusted, (15, 15), 0)\n",
    "\n",
    "            # Step 4: Lower brightness to simulate reduced daytime vision sensitivity\n",
    "            brightness = -30\n",
    "            result = cv2.convertScaleAbs(blurred, beta=brightness)\n",
    "        \n",
    "        elif image_filter == BIRD:\n",
    "            # Step 1: Simulate tetrachromatic (enhanced color) vision by boosting saturation and brightness\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Increase saturation and brightness\n",
    "            hsv[:, :, 1] = np.clip(hsv[:, :, 1] * 1.5, 0, 255)  # Saturation (color intensity)\n",
    "            hsv[:, :, 2] = np.clip(hsv[:, :, 2] * 1.3, 0, 255)  # Brightness\n",
    "\n",
    "            # Step 2: Simulate UV light perception by shifting hue\n",
    "            hsv[:, :, 0] = (hsv[:, :, 0] + 20) % 180  # Shift hue towards violet/blue\n",
    "\n",
    "            # Convert back to BGR after color adjustments\n",
    "            color_adjusted = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "            # Step 3: Sharpen the image to reflect high visual acuity\n",
    "            kernel = np.array([[0, -1, 0],\n",
    "                            [-1, 5, -1],\n",
    "                            [0, -1, 0]])  # Sharpening kernel\n",
    "            sharpened = cv2.filter2D(color_adjusted, -1, kernel)\n",
    "\n",
    "            # Step 4: Apply a slight fisheye effect to simulate a wide-angle field of view\n",
    "            height, width = sharpened.shape[:2]\n",
    "            K = np.array([[width, 0, width//2],\n",
    "                        [0, height, height//2],\n",
    "                        [0, 0, 1]])\n",
    "            D = np.array([-0.2, 0.1, 0, 0])  # Distortion coefficients for a subtle fisheye effect\n",
    "            map1, map2 = cv2.initUndistortRectifyMap(K, D, None, K, (width, height), 5)\n",
    "            result = cv2.remap(sharpened, map1, map2, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        mode_text = mode_names[image_filter]\n",
    "        cv2.putText(result, mode_text, (450, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(window_name, result)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"Q\") or key == ord(\"q\") or key == 27:\n",
    "            alive = False  \n",
    "        elif key == ord(\"H\") or key == ord(\"h\"):\n",
    "            image_filter = HUMAN   \n",
    "        elif key == ord(\"S\") or key == ord(\"s\"):\n",
    "            image_filter = SNAKE\n",
    "        elif key == ord(\"D\") or key == ord(\"d\"):\n",
    "            image_filter = DOG\n",
    "        elif key == ord(\"I\") or key == ord(\"i\"):\n",
    "            image_filter = INSECT\n",
    "        elif key == ord(\"E\") or key == ord(\"e\"):\n",
    "            image_filter = ELEPHANT\n",
    "        elif key == ord(\"B\") or key == ord(\"b\"):\n",
    "            image_filter = BIRD\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        break\n",
    "\n",
    "source.release()\n",
    "cv2.destroyWindow(window_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-unreal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
